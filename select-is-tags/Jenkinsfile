import groovy.json.JsonSlurper
import net.sf.json.JSONObject
import groovy.json.JsonBuilder

// This will be populated with the user-selected Image Tag
String userSelectedTag = null

// ImageStream names. These should match the image names created by TeamCity
env.DB_IMAGE_STREAM  = "${env.APPLICATION_PREFIX}-flying-squirrel-migrator"
env.APP_IMAGE_STREAM = "${env.APPLICATION_PREFIX}-web"

// Name of the file where we store the downloaded DB ImageStream data
env.DB_IMAGE_STREAM_METADATA_FILE = 'db-image-stream-metadata.json'

/**
 * Debugging utility
 */
String _debugPrintObject(object) { new JsonBuilder(object).toPrettyString() }

/**
 * Saves ImageStream metadata for the given name into a file in the workspace
 */
void initDbImageStreamMetaData(String imageStreamName) {
    // Get ImageStream data in JSON format
    //
    String result = sh( 
      script: "oc get is ${imageStreamName} -o json", 
      returnStdout: true 
    )

    // Save the data into a file in our workspace. This allows us to easily access this info from anywhere in the build
    //
    writeJSON(
      file: env.DB_IMAGE_STREAM_METADATA_FILE, 
      json: new JSONObject(new JsonSlurper().parseText(result))
    )
}

/**
 * Reads ImageStream metadata from file
 */
def getImageStreamMetadata() {
  readJSON(file: env.DB_IMAGE_STREAM_METADATA_FILE)
}

/**
 * Returns a list of '\n' separated tags available in the specified image stream
 */
String extractImageStreamTags() {
    List tags = getImageStreamMetadata().spec?.tags
    if ( tags && !tags.isEmpty() ) {
      String parsedOutTags = tags
                              .collect { it.name }
                              .join('\n');
      
      echo """
========= Available Tags =========
${parsedOutTags}
==================================
"""
      return parsedOutTags
    }
    else {
      error("Could not fetch any tags from Project: '${env.PROJECT_NAME}', ImageStream: '${env.DB_IMAGE_STREAM}'")
    }
}



/** ************************************************************************************
 *                               Pipeline code starts here
 * *************************************************************************************/
try {
  node {

    stage("Detect OpenShift Project Name") {
      openshift.withCluster() {
          openshift.withProject(null) {
            env.PROJECT_NAME = openshift.project()
            echo "Detected OpenShift Project: ${env.PROJECT_NAME}"
          }
      }
    }


    stage("Fetch Image Tags") {
      timeout(time: 20, unit: 'SECONDS') {
        openshift.withCluster() {
          openshift.withProject(env.PROJECT_NAME) {
            // Initialize ImageStream metadata
            //
            initDbImageStreamMetaData(env.DB_IMAGE_STREAM);
          }
        }  
      }
    }
    
    
    stage("User Action: Image Tag Selection") {
        timeout(time: 5, unit: 'MINUTES') {
          echo "Waiting for user to select a tag..."

          // Pops up a window with a drop-down to collect user input
          //
          userSelectedTag = input(
            message: 'Select the Build Number you wish to deploy', 
            ok: 'Next', 
            parameters: [
              choice(name: 'IMAGE_TAG', choices: extractImageStreamTags(), description: 'Build Number to deploy')
            ]
          )
        }
    }
    
    
//     stage("Run DB Migrations") {
//         echo """
// =============================
// User selected tag: ${userSelectedTag}
// =============================
// """
//         final String MIGRATIONS_JOB_NAME = "${env.DB_IMAGE_STREAM}-job"

//         timeout(time: 5, unit: 'MINUTES') {
//           openshift.withCluster() {
//             openshift.withProject(env.PROJECT_NAME) {

//               // Delete this job if it already exists
//               //
//               def jobSelector = openshift.selector("job", MIGRATIONS_JOB_NAME)
//               if ( jobSelector.exists() ) {
//                 echo "Deleting pre-existing ${MIGRATIONS_JOB_NAME}..."
//                 jobSelector.delete()
//               }

//               // Allow usage of the Image Stream with our Job, which is a Kubernetes Resource, rather than a native OpenShift resource
//               //    https://docs.openshift.com/container-platform/3.11/dev_guide/managing_images.html#using-is-with-k8s
//               //
//               sh "oc set image-lookup ${env.DB_IMAGE_STREAM}"

//               // Create and run the job
//               //
//               jobSelector = openshift.create([
//                 "apiVersion": "batch/v1",
//                 "kind": "Job",

//                 "metadata": [
//                   "name": MIGRATIONS_JOB_NAME,
//                   "namespace": env.PROJECT_NAME
//                 ],

//                 "spec": [
//                   "backoffLimit": 1,
//                   "completions": 1,
//                   "parallelism": 1,

//                   "template": [
//                     "spec": [
//                       "containers": [
//                         [
//                           "name": MIGRATIONS_JOB_NAME,
//                           "env": [
//                             ["name": "DB_ENV_NAME",  "value": env.DB_ENV_NAME],
//                             ["name": "FLYWAY_TASKS", "value": "info"] // Just for testing
//                           ],
//                           "image": "${env.DB_IMAGE_STREAM}:${userSelectedTag}",
//                           "imagePullPolicy": "IfNotPresent"
//                         ]
//                       ],
//                       "restartPolicy": "Never"
//                     ]

//                   ]
//                 ]
//               ])
//               echo "Job Created:"
//               jobSelector.describe()

//               // Get the Pod scheduled to run this job, and wait for it to run or fail
//               //
//               echo "Finding related pod:"
//               def podSelector = jobSelector.related( 'pods' )
//               podSelector.describe()
//               podSelector.untilEach {
//                 def podStatus = it.object().status
//                 echo "${MIGRATIONS_JOB_NAME} container statuses:\n ${_debugPrintObject(podStatus.containerStatuses)}"
//                 ['Running', 'Failed'].contains(podStatus.phase)
//               }

//               // Follow the logs of this pod
//               //
//               podSelector.logs("--follow")
//             }
//           }
//         }

//         echo "Database Migrations applied successfully!"
//     }


    stage("Deploy Application") {
        timeout(time: 5, unit: 'MINUTES') {
          openshift.withCluster() {
            openshift.withProject(env.PROJECT_NAME) {
              
              // Patch the DeploymentConfig object on the server
              //
              def deploymentConfig = openshift.selector("dc/${env.APPLICATION_PREFIX}-web").object()
              def imageChangeParams = deploymentConfig.spec.triggers[1].imageChangeParams
              imageChangeParams.from['name'] = "${env.APP_IMAGE_STREAM}:${userSelectedTag}"
              echo "Patching DeploymentConfig in the OpenShift Project:\n${_debugPrintObject(imageChangeParams)}"
              openshift.apply(deploymentConfig)

              // Re-deploy the application
              //
              echo "Starting application deployment..."
              openshift.selector("dc/${env.APPLICATION_PREFIX}-web").rollout().latest()
              def latestDeploymentVersion = openshift.selector("dc/${env.APPLICATION_PREFIX}-web").object().status.latestVersion
              def replicationController   = openshift.selector("rc/${env.APPLICATION_PREFIX}-web-${latestDeploymentVersion}")
              replicationController.untilEach(1){
                  def rcMap = it.object()
                  echo "Replication Controller Status:\n ${_debugPrintObject(rcMap.status)}"
                  return (rcMap.status.replicas.equals(rcMap.status.readyReplicas))
              }
            }
          }
        }
    }

  }
} catch (err) {
  echo "in catch block"
  echo "Caught: ${err}"
  currentBuild.result = 'FAILURE'
  throw err
}