import groovy.json.JsonSlurperClassic
import groovy.json.JsonBuilder
import net.sf.json.JSONObject
import java.util.regex.Matcher


// This global will be populated with the user-selected Image Tag
//
String userSelectedTag = null

// ImageStream names. These should match the image names created by TeamCity
//
env.DB_IMAGE_STREAM  = "${env.APPLICATION_PREFIX}-flying-squirrel-migrator"
env.APP_IMAGE_STREAM = "${env.APPLICATION_PREFIX}-web"
String webAppName = env.APP_IMAGE_STREAM

// Name of the file where we store the downloaded DB ImageStream data
//
env.DB_IMAGE_STREAM_METADATA_FILE = 'db-image-stream-metadata.json'



/**
 * Debugging utility
 */
String _debugPrintObject(object) { new JsonBuilder(object).toPrettyString() }

/**
 * Saves ImageStream metadata for the given name into a file in the workspace
 */
void _initDbImageStreamMetaData(String imageStreamName) {
    // Get ImageStream data in JSON format
    //
    String result = sh( 
      script: "oc get is ${imageStreamName} -o json", 
      returnStdout: true 
    )

    // Save the data into a file in our workspace. This allows us to easily access this info from anywhere in the build
    //
    writeJSON(
      file: env.DB_IMAGE_STREAM_METADATA_FILE, 
      json: new JSONObject(new JsonSlurperClassic().parseText(result))
    )
}

/**
 * Reads ImageStream metadata from file
 */
def _getImageStreamMetadata() {
  readJSON(file: env.DB_IMAGE_STREAM_METADATA_FILE)
}

/**
 * Returns a list of '\n' separated tags available in the specified image stream
 */
String _extractImageStreamTags() {
    List tags = _getImageStreamMetadata().spec?.tags
    if ( tags && !tags.isEmpty() ) {
      String parsedOutTags = tags
                              .collect { it.name }
                              .reverse()
                              .join('\n');
      
      echo """
========= Available Tags =========
${parsedOutTags}
==================================
"""
      return parsedOutTags
    }
    else {
      error("Could not fetch any tags from Project: '${env.PROJECT_NAME}', ImageStream: '${env.DB_IMAGE_STREAM}'")
    }
}

/**
 * Executes Flying Squirrel Migrator Gradle tasks from the specified Docker image, with specified command-line parameters.
 *
 * Returns the console output from the executed Docker image
 */
String _runFlyingSquirrelMigratorJob(String imageStreamName, String imageStreamTag, String envName, String tasks) {
  final String MIGRATIONS_JOB_NAME = "${imageStreamName}-job"

  // Delete this job if it already exists
  //
  def jobSelector = openshift.selector("job", MIGRATIONS_JOB_NAME)
  if ( jobSelector.exists() ) {
    echo "Deleting pre-existing ${MIGRATIONS_JOB_NAME}..."
    jobSelector.delete()
  }

  // Allow usage of the Image Stream with our Job, which is a Kubernetes Resource, rather than a native OpenShift resource
  //    https://docs.openshift.com/container-platform/3.11/dev_guide/managing_images.html#using-is-with-k8s
  //
  sh "oc set image-lookup ${imageStreamName}"

  // Create and run the job
  //
  jobSelector = openshift.create([
    "apiVersion": "batch/v1",
    "kind": "Job",

    "metadata": [
      "name": MIGRATIONS_JOB_NAME
    ],

    "spec": [
      "backoffLimit": 1,
      "completions": 1,
      "parallelism": 1,

      "template": [
        "spec": [
          "containers": [
            [
              "name": MIGRATIONS_JOB_NAME,
              "env": [
                ["name": "DB_ENV_NAME",  "value": envName],
                ["name": "FLYWAY_TASKS", "value": tasks]
              ],
              "image": "${imageStreamName}:${imageStreamTag}",
              "imagePullPolicy": "IfNotPresent"
            ]
          ],
          "restartPolicy": "Never"
        ]

      ]
    ]
  ])
  echo "Job Created:"
  jobSelector.describe()

  // Get the Pod scheduled to run this job, and wait for it to run or fail
  //
  echo "Finding related pod:"
  def podSelector = jobSelector.related('pods')
  podSelector.describe()
  podSelector.untilEach {
    def podStatus = it.object().status
    echo "${MIGRATIONS_JOB_NAME} container statuses:\n ${_debugPrintObject(podStatus.containerStatuses)}"
    ['Running', 'Failed'].contains(podStatus.phase)
  }

  // Follow the logs of this pod
  //
  def result = podSelector.logs("--follow")
  return result?.actions?.last()?.out ?: ""
}

/**
 * This had to be broken out into a method, b/c Matcher is not Serializable, so we had to tell Jenkins
 * not to attempt saving the state of the objects in this method
 */
@NonCPS
def _parseJdbcConnectInfo(String consoleOutput) {
  def matcher = (consoleOutput =~ /(?ms).+JDBC connect info.+?(\{.*\})/)

  matcher.hasGroup() \
    && matcher.size() == 1 \
    && matcher[0].size() == (1+1) ? 
        new JsonSlurperClassic().parseText(matcher[0][1]) : false
}

/** ************************************************************************************
 *                               Pipeline code starts here
 * *************************************************************************************/
try {
  node {

    stage("Detect OpenShift Project Name") {
      openshift.withCluster() {
          openshift.withProject(null) {
            env.PROJECT_NAME = openshift.project()
            echo "Detected OpenShift Project: ${env.PROJECT_NAME}"
          }
      }
    }


    stage("Fetch Image Tags") {
      timeout(time: 20, unit: 'SECONDS') {
        openshift.withCluster() {
          openshift.withProject(env.PROJECT_NAME) {

            // Initialize ImageStream metadata
            //
            _initDbImageStreamMetaData(env.DB_IMAGE_STREAM);

          }
        }  
      }
    }
    
    
    stage("User Action: Image Tag Selection") {
        timeout(time: 5, unit: 'MINUTES') {
          echo "Waiting for user to select a tag..."

          // Pops up a window with a drop-down to collect user input
          //
          //userSelectedTag = 'Build-6.3.0.4'
          userSelectedTag = input(
            message: 'Select the Build Number you wish to deploy', 
            ok: 'Next', 
            parameters: [
              choice(name: 'IMAGE_TAG', choices: _extractImageStreamTags(), description: 'Build Number to deploy')
            ]
          )
          echo """
=============================
User selected tag: ${userSelectedTag}
=============================
"""
        }
    }
    
    
    stage("Run DB Migrations") {
        timeout(time: 5, unit: 'MINUTES') {
          openshift.withCluster() {
            openshift.withProject(env.PROJECT_NAME) {
              _runFlyingSquirrelMigratorJob(env.DB_IMAGE_STREAM, userSelectedTag, env.DB_ENV_NAME, "info")
            }
          }
        }

        echo "Database Migrations applied successfully!"
    }


    stage("Create Web Application") {
        timeout(time: 1, unit: 'MINUTES') {
          openshift.withCluster() {
            openshift.withProject(env.PROJECT_NAME) {

              // Get JDBC Connect Info from the Flying Squirrel Migrator image
              //
              String consoleOutput = _runFlyingSquirrelMigratorJob(env.DB_IMAGE_STREAM, userSelectedTag, env.DB_ENV_NAME, "jdbcConnectInfo")
              def jdbcConnectInfo = _parseJdbcConnectInfo(consoleOutput)
              if ( jdbcConnectInfo ) {
                echo "Deploying application with the following Datasource configuration:\n${_debugPrintObject(jdbcConnectInfo)}"

                // Create all resources for the app
                //
                if ( !openshift.selector("dc", webAppName).exists() ) {
                  echo "${webAppName} does not exist in ${env.PROJECT_NAME}. Creating..."                

                  // Just in case, delete everything first
                  //
                  sh "oc delete all,configmap --selector app=${env.APPLICATION_PREFIX}"

                  // Create brand new resources using the template
                  //
                  def processedObjects = openshift.process(
                    readFile("${workspace}@script/drydock-manual-deployment-pipeline/drydock-manual-deployment-template.yml"), 
                    "-p", "APPLICATION_PREFIX=${env.APPLICATION_PREFIX}",
                    "-p", "DATASOURCE_URL=${jdbcConnectInfo.DATASOURCE_URL}",
                    "-p", "DATASOURCE_USERNAME=${jdbcConnectInfo.DATASOURCE_USERNAME}",
                    "-p", "DATASOURCE_PASSWORD=${jdbcConnectInfo.DATASOURCE_PASSWORD}"
                  )

                  def fromJSON = openshift.create( processedObjects )
                  echo "Created objects from JSON file: ${fromJSON.names()}"
                }
                else {
                  echo "DeploymentConfig for ${webAppName} already exists. Skipping template processing, but updating configmap..."
                  def configmap = openshift.selector("configmap", "${env.APPLICATION_PREFIX}-config-map").object()
                  configmap['data'] = jdbcConnectInfo
                  openshift.apply(configmap)
                  echo _debugPrintObject(configmap)
                }
              }
              else {
                error("Could not parse JDBC Connect Info from: \n${consoleOutput}")
              }
            }
          }
        }
    }


    stage("Deploy Application") {
        timeout(time: 5, unit: 'MINUTES') {
          openshift.withCluster() {
            openshift.withProject(env.PROJECT_NAME) {
              
              // Patch the DeploymentConfig object on the server
              //
              def deploymentConfigSelector = openshift.selector("dc", webAppName)
              def imageChangeParams = deploymentConfigSelector.object().spec.triggers[1].imageChangeParams
              imageChangeParams.from['name'] = "${env.APP_IMAGE_STREAM}:${userSelectedTag}"
              echo "Patched DeploymentConfig 'imageChangeParams':\n${_debugPrintObject(imageChangeParams)}"
              openshift.apply(deploymentConfigSelector.object())

              // Patch the Route and Probes in the DeploymentConfig to update the Context Root with UPPER CASE application name
              //
              def newContextRoot = "/${env.APPLICATION_PREFIX.toUpperCase()}"
              sh (/oc patch route ${webAppName} -p '
                {
                  "spec": {
                    "path": "${newContextRoot}"
                  }
                }'
              /)
              echo "Patched Route:"
              openshift.selector("route", webAppName).describe()

              sh (/oc patch dc ${webAppName} -p '
                {
                  "spec": {
                    "template": {
                      "spec": {
                        "containers": [
                          {
                            "name": "${webAppName}",
                            "livenessProbe": {
                              "httpGet": {
                                "path": "${newContextRoot}\/login.jsf"
                              }
                            },
                            "readinessProbe": {
                              "httpGet": {
                                "path": "${newContextRoot}\/login.jsf"
                              }
                            }
                          }
                        ]
                      }
                    }
                  }
                }'
              /)

              def dcContainer = deploymentConfigSelector.object().spec.template.spec.containers[0]
              echo "Patched Liveness Probe: \n ${_debugPrintObject(dcContainer.livenessProbe)}"
              echo "Patched Readiness Probe:\n ${_debugPrintObject(dcContainer.readinessProbe)}"

              // Start application re-deploy
              //
              echo "Starting application deployment..."
              def rolloutManager = deploymentConfigSelector.rollout()
              rolloutManager.latest() // Start the rollout

              // Monitor the ReplicationController doing the re-deploy
              //
              def latestDeploymentVersion = deploymentConfigSelector.object().status.latestVersion
              String replicationControllerName = "${webAppName}-${latestDeploymentVersion}"
              echo "Monitoring Replication Controller '${replicationControllerName}'..."
              def replicationController = openshift.selector("rc", replicationControllerName)
              replicationController.untilEach(1) {
                  def rcStatus = it.object().status
                  echo "Replication Controller Status:\n ${_debugPrintObject(rcStatus)}"
                  return rcStatus.replicas == rcStatus.readyReplicas
              }
              rolloutManager.status("-w")

              // Print the logs of the pod where the application is now running
              //
              def podSelector = deploymentConfigSelector.related('pods')
              echo "Application deployed inside this pod:"
              podSelector.describe()
              echo """
====================================
Application Startup Logs
====================================              
"""
              podSelector.logs()
            }
          }
        }
    }

  }
} catch (err) {
  echo "in catch block"
  echo "Caught: ${err}"
  currentBuild.result = 'FAILURE'
  throw err
}